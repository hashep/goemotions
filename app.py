import streamlit as st
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.schema import Document
from langchain.document_loaders import PyPDFLoader
from transformers import pipeline
from datasets import load_dataset


emotion_classifier = pipeline(
    "text-classification",
    model="j-hartmann/emotion-english-distilroberta-base",
    return_all_scores=False
)

@st.cache_data
def load_goemotions_docs(sample_size=200):
    dataset = load_dataset("go_emotions", "simplified", split="train")
    samples = dataset.shuffle(seed=42).select(range(sample_size))
    docs = []
    for item in samples:
        text = item["text"]
        emotions = item["labels"]
        if emotions:
            docs.append(Document(page_content=f"ë¬¸ì¥: {text}\nê°ì • ë¼ë²¨(ë²ˆí˜¸): {emotions}"))
    return docs

def extract_text_from_pdf(uploaded_file):
    with open("temp.pdf", "wb") as f:
        f.write(uploaded_file.read())
    loader = PyPDFLoader("temp.pdf")
    documents = loader.load()
    return " ".join([doc.page_content for doc in documents])

def classify_emotion(text):
    result = emotion_classifier(text, truncation=True, max_length=512)[0]
    return result['label'], result['score']

def create_vectorstore(user_text, emotion_label, goemotion_docs):
    user_doc = Document(page_content=f"ì¼ê¸° ë‚´ìš©: {user_text}\nê°ì • ë¶„ì„: {emotion_label}")
    all_docs = goemotion_docs + [user_doc]
    return FAISS.from_documents(all_docs, OpenAIEmbeddings())

def create_chatbot(vectorstore):
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    llm = OpenAI(
        temperature=0.7,
        openai_api_key=st.secrets["openai"]["api_key"]
    )
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        memory=memory
    )
    return qa_chain

st.set_page_config(page_title="ê°ì • ì¼ê¸° ì±—ë´‡", page_icon="ğŸ“˜")
st.title("ê°ì • ì¼ê¸° ë¶„ì„ ì±—ë´‡")
st.write("PDF ì¼ê¸° ì—…ë¡œë“œ")

uploaded_file = st.file_uploader("PDF ì¼ê¸° íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

if uploaded_file:
    with st.spinner("PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘"):
        diary_text = extract_text_from_pdf(uploaded_file)
        st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")

    with st.spinner("ê°ì • ë¶„ì„ ì¤‘"):
        label, score = classify_emotion(diary_text)
        st.markdown(f"### ê°ì • ê²°ê³¼: **{label}** (ì‹ ë¢°ë„: {score:.2f})")

    with st.spinner("GoEmotions ë°ì´í„° ë¡œë”© ì¤‘"):
        goemotion_docs = load_goemotions_docs()

    with st.spinner("RAG ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘"):
        vectorstore = create_vectorstore(diary_text, label, goemotion_docs)
        chatbot = create_chatbot(vectorstore)

    st.markdown("---")
    st.subheader("ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”")
    user_input = st.text_input("ì§ˆë¬¸:")
    if user_input:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘"):
            response = chatbot.run(user_input)
            st.write(response)
